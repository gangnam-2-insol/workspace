from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import uuid
import json
import re
from llm_service import LLMService  # ë‚´ë¶€ì— LLM í˜¸ì¶œ ë¡œì§ í¬í•¨
from question_data import get_questions_for_page  # ê¸°ì¡´ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°ìš©

router = APIRouter()
sessions: Dict[str, Dict[str, Any]] = {}

class ChatbotRequest(BaseModel):
    page: str
    user_input: str
    session_id: Optional[str] = None

class ChatbotResponse(BaseModel):
    field: Optional[str] = None
    value: Optional[str] = None
    message: str
    session_id: Optional[str] = None
    mode: str = "normal"  # "normal", "guided", "chat"

class SessionStartRequest(BaseModel):
    page: str
    questions: Optional[List[Dict[str, str]]] = None  # ì™¸ë¶€ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ë™ì  ì…ë ¥ í—ˆìš©

class SessionStartResponse(BaseModel):
    session_id: str
    current_field: str
    question: str

def detect_keywords(user_input: str) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì ì…ë ¥ì—ì„œ í‚¤ì›Œë“œë¥¼ ê°ì§€í•˜ì—¬ ëª¨ë“œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    """
    input_lower = user_input.lower()
    
    # í‚¤ì›Œë“œ íŒ¨í„´ ì •ì˜ (ìš°ì„ ìˆœìœ„ ìˆœ)
    keywords = {
        "recruitment": [
            "ì±„ìš©", "êµ¬ì¸", "ê³µê³ ", "ëª¨ì§‘", "ì±„ìš©ê³µê³ ", "êµ¬ì¸ê³µê³ ", "ì±„ìš©ì •ë³´", 
            "ì§ë¬´", "ì—…ë¬´", "ê·¼ë¬´", "ì—°ë´‰", "ê¸‰ì—¬", "ë³µë¦¬í›„ìƒ", "ê·¼ë¬´ì§€", "ë§ˆê°ì¼",
            "ìê²©ìš”ê±´", "ìš°ëŒ€ì‚¬í•­", "í•„ìˆ˜ì¡°ê±´", "ì„ í˜¸ì¡°ê±´"
        ],
        "resume": [
            "ì´ë ¥ì„œ", "ìê¸°ì†Œê°œì„œ", "ê²½ë ¥", "í•™ë ¥", "í¬íŠ¸í´ë¦¬ì˜¤", "ìŠ¤í‚¬", "ê¸°ìˆ ìŠ¤íƒ",
            "í”„ë¡œì íŠ¸", "ìˆ˜ìƒ", "ìê²©ì¦", "ì–¸ì–´ëŠ¥ë ¥", "ì™¸êµ­ì–´", "ì»´í“¨í„°í™œìš©ëŠ¥ë ¥"
        ],
        "interview": [
            "ë©´ì ‘", "ì¸í„°ë·°", "ì§ˆë¬¸", "í‰ê°€", "ë©´ì ‘ê´€", "ë©´ì ‘ì", "ë©´ì ‘ì¼ì •",
            "ë©´ì ‘ì‹œê°„", "ë©´ì ‘ì¥ì†Œ", "ë©´ì ‘ì¤€ë¹„", "ë©´ì ‘íŒ", "ë©´ì ‘ì§ˆë¬¸"
        ],
        "dashboard": [
            "ëŒ€ì‹œë³´ë“œ", "í˜„í™©", "í†µê³„", "í˜„ì¬ìƒí™©", "ìš”ì•½", "ê°œìš”", "í˜„ì¬ìƒíƒœ",
            "ì§€ì›ì", "ì§€ì›í˜„í™©", "ì±„ìš©í˜„í™©", "ë©´ì ‘í˜„í™©", "í†µê³„ë³´ê¸°"
        ],
        "help": [
            "ë„ì›€", "ë„ì›€ë§", "ì‚¬ìš©ë²•", "ê°€ì´ë“œ", "ì„¤ëª…", "ì–´ë–»ê²Œ", "ë°©ë²•",
            "ì‚¬ìš©ë°©ë²•", "ì´ìš©ë²•", "ë„ì›€ì£¼ì„¸ìš”", "ì•Œë ¤ì£¼ì„¸ìš”", "ê°€ë¥´ì³ì£¼ì„¸ìš”"
        ],
        "general_chat": [
            "ì•ˆë…•", "ë°˜ê°‘", "ê³ ë§ˆì›Œ", "ê°ì‚¬", "ì¢‹ì•„", "ê´œì°®ì•„", "ë§ì•„", "ê·¸ë˜",
            "ë„¤", "ì‘", "ì•Œê² ì–´", "ì´í•´í–ˆì–´", "ê·¸ë ‡êµ¬ë‚˜", "ê·¸ëŸ°ê°€", "ì•„í•˜"
        ],
        "system": [
            "ì‹œìŠ¤í…œ", "ì˜¤ë¥˜", "ì—ëŸ¬", "ë¬¸ì œ", "ë²„ê·¸", "ì‘ë™ì•ˆë¨", "ì•ˆë¼", "ì•ˆë¨",
            "ë¡œê·¸ì¸", "íšŒì›ê°€ì…", "ë¹„ë°€ë²ˆí˜¸", "ì•„ì´ë””", "ê³„ì •"
        ]
    }
    
    # ë¬¸ë§¥ ê¸°ë°˜ í‚¤ì›Œë“œ (ë” ì •í™•í•œ ê°ì§€ë¥¼ ìœ„í•´)
    context_keywords = {
        "question_words": ["ë­", "ë¬´ì—‡", "ì–´ë–¤", "ì–´ë–»ê²Œ", "ì™œ", "ì–¸ì œ", "ì–´ë””", "ëˆ„ê°€", "ëª‡"],
        "action_words": ["í•´ì£¼ì„¸ìš”", "í•´ì¤˜", "ì•Œë ¤ì¤˜", "ë³´ì—¬ì¤˜", "ì°¾ì•„ì¤˜", "ì¶”ì²œí•´ì¤˜"],
        "confirmation_words": ["ë§ë‚˜", "ë§ì•„", "ê·¸ë˜", "ë„¤", "ì‘", "ì¢‹ì•„", "ê´œì°®ì•„"]
    }
    
    detected_keywords = []
    detected_categories = []
    
    # ê¸°ë³¸ í‚¤ì›Œë“œ ê°ì§€
    for category, keyword_list in keywords.items():
        for keyword in keyword_list:
            if keyword in input_lower:
                detected_keywords.append(keyword)
                detected_categories.append(category)
                break
    
    # ë¬¸ë§¥ í‚¤ì›Œë“œ ê°ì§€
    context_detected = []
    for context_type, context_list in context_keywords.items():
        for keyword in context_list:
            if keyword in input_lower:
                context_detected.append(context_type)
                break
    
    # ëª¨ë“œ ê²°ì • ë¡œì§ ê°œì„ 
    if detected_categories:
        # ìš°ì„ ìˆœìœ„: ê¸°ëŠ¥ë³„ í‚¤ì›Œë“œ > ë„ì›€ë§ > ì¼ë°˜ ì±„íŒ…
        if any(k in detected_categories for k in ["recruitment", "resume", "interview"]):
            return {"mode": "guided", "keywords": detected_keywords, "categories": detected_categories}
        elif any(k in detected_categories for k in ["dashboard", "help", "system"]):
            return {"mode": "guided", "keywords": detected_keywords, "categories": detected_categories}
        elif "general_chat" in detected_categories:
            return {"mode": "chat", "keywords": detected_keywords, "categories": detected_categories}
    
    # í‚¤ì›Œë“œê°€ ì—†ì§€ë§Œ ë¬¸ë§¥ìƒ ì§ˆë¬¸ì¸ ê²½ìš°
    if context_detected:
        if "question_words" in context_detected:
            # ì§ˆë¬¸ í˜•íƒœì´ì§€ë§Œ íŠ¹ì • í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¼ë°˜ ì±„íŒ…
            return {"mode": "chat", "keywords": [], "categories": [], "context": context_detected}
        elif "action_words" in context_detected:
            # ìš”ì²­ í˜•íƒœì´ì§€ë§Œ íŠ¹ì • í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¼ë°˜ ì±„íŒ…
            return {"mode": "chat", "keywords": [], "categories": [], "context": context_detected}
    
    # ì•„ë¬´ í‚¤ì›Œë“œë„ ì—†ìœ¼ë©´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ ì²˜ë¦¬
    return {"mode": "chat", "keywords": [], "categories": [], "context": context_detected}

# ì„¸ì…˜ ì‹œì‘ (ì™¸ë¶€ì—ì„œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ì£¼ì… ê°€ëŠ¥)
@router.post("/start", response_model=SessionStartResponse)
async def start_session(request: SessionStartRequest):
    # ì™¸ë¶€ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
    questions = request.questions or get_questions_for_page(request.page)
    if not questions:
        raise HTTPException(status_code=404, detail="í˜ì´ì§€ ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    session_id = str(uuid.uuid4())
    sessions[session_id] = {
        "page": request.page,
        "questions": questions,
        "current_index": 0,
        "current_field": questions[0]["field"],
        "completed_fields": [],
        "conversation_history": [],
        "mode": "guided"  # ê¸°ë³¸ ëª¨ë“œ
    }
    return SessionStartResponse(
        session_id=session_id,
        current_field=questions[0]["field"],
        question=questions[0]["question"]
    )

@router.post("/ask", response_model=ChatbotResponse)
async def ask_chatbot(request: ChatbotRequest):
    if not request.session_id or request.session_id not in sessions:
        raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ì…ë‹ˆë‹¤")

    session = sessions[request.session_id]
    
    # í‚¤ì›Œë“œ ê°ì§€ ë° ëª¨ë“œ ê²°ì •
    keyword_result = detect_keywords(request.user_input)
    current_mode = keyword_result["mode"]
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì‚¬ìš©ì ì…ë ¥ ì €ì¥
    session["conversation_history"].append({
        "role": "user",
        "content": request.user_input,
        "field": session.get("current_field"),
        "mode": current_mode
    })

    llm_service = LLMService()
    
    if current_mode == "chat":
        # ì¼ë°˜ ì±„íŒ… ëª¨ë“œ - ììœ ë¡œìš´ ëŒ€í™”
        response = await handle_chat_mode(request, session, llm_service)
    else:
        # ê°€ì´ë“œ ëª¨ë“œ - ê¸°ì¡´ ê¸°ëŠ¥ë³„ ì§ˆë¬¸ ì²˜ë¦¬
        response = await handle_guided_mode(request, session, llm_service)
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì±—ë´‡ ì‘ë‹µ ì €ì¥
    session["conversation_history"].append({
        "role": "bot",
        "content": response["message"],
        "field": response.get("field"),
        "mode": current_mode
    })

    return ChatbotResponse(
        field=response.get("field"),
        value=response.get("value"),
        message=response["message"],
        session_id=request.session_id,
        mode=current_mode
    )

async def handle_chat_mode(request: ChatbotRequest, session: Dict, llm_service: LLMService) -> Dict[str, Any]:
    """
    ì¼ë°˜ ì±„íŒ… ëª¨ë“œ ì²˜ë¦¬ - ììœ ë¡œìš´ ëŒ€í™”
    """
    chat_prompt = f"""
ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤.
ì‚¬ìš©ìëŠ” ì¸ì‚¬ë‹´ë‹¹ìë¡œ, êµ¬ì¸êµ¬ì§ ì—…ë¬´ë¥¼ ë‹´ë‹¹í•˜ê³  ìˆìŠµë‹ˆë‹¤.

**ë‹¹ì‹ ì˜ ì—­í• :**
- êµ¬ì¸êµ¬ì§ ì „ë¬¸ê°€ë¡œì„œ ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
- ì¸ì‚¬ë‹´ë‹¹ìì˜ ì—…ë¬´ íš¨ìœ¨ì„± í–¥ìƒ ì§€ì›
- ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìŠ¤íƒ€ì¼ ìœ ì§€
- êµ¬ì¸êµ¬ì§ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•œ ì „ë¬¸ì ì¸ ë‹µë³€

**êµ¬ì¸êµ¬ì§ ì „ë¬¸ ì§€ì‹:**
- ì±„ìš©ê³µê³  ì‘ì„± ë° ìµœì í™”
- ì´ë ¥ì„œ ê²€í†  ë° í‰ê°€ ë°©ë²•
- ë©´ì ‘ ì§ˆë¬¸ ë° í‰ê°€ ê¸°ì¤€
- êµ¬ì¸êµ¬ì§ íŠ¸ë Œë“œ ë° ë²•ê·œ
- ì¸ì‚¬ ê´€ë¦¬ ë° ì¡°ì§ ë¬¸í™”

**ì‘ë‹µ ìŠ¤íƒ€ì¼:**
- ì¹œê·¼í•˜ê³  ì¡´ëŒ“ë§ ì‚¬ìš©
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
- í•„ìš”ì‹œ ì˜ˆì‹œë‚˜ ì‚¬ë¡€ í¬í•¨
- ì‚¬ìš©ìì˜ ìƒí™©ì— ë§ëŠ” ë§ì¶¤í˜• ë‹µë³€
- ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…

**í˜„ì¬ í˜ì´ì§€**: {request.page}
**ì‚¬ìš©ì ì…ë ¥**: {request.user_input}

ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©°, êµ¬ì¸êµ¬ì§ ê´€ë ¨ ì§ˆë¬¸ì´ë‚˜ ì¼ë°˜ì ì¸ ëŒ€í™” ëª¨ë‘ì— ì¹œì ˆí•˜ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""

    try:
        # ì¼ë°˜ ì±„íŒ…ìš© ë©”ì‹œì§€ êµ¬ì„±
        context_messages = [
            {"role": "user", "parts": [chat_prompt]}
        ]
        
        # ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 4í„´)
        if session["conversation_history"]:
            recent_history = session["conversation_history"][-8:]  # ìµœê·¼ 4í„´
            for msg in recent_history:
                if msg["role"] == "user":
                    context_messages.append({"role": "user", "parts": [msg["content"]]})
                elif msg["role"] == "bot":
                    context_messages.append({"role": "model", "parts": [msg["content"]]})
        
        # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
        context_messages.append({"role": "user", "parts": [request.user_input]})
        
        # Gemini API í˜¸ì¶œ
        response = llm_service.client.generate_content(context_messages)
        
        return {
            "field": None,
            "value": None,
            "message": response.text
        }
        
    except Exception as e:
        return {
            "field": None,
            "value": None,
            "message": f"ì£„ì†¡í•©ë‹ˆë‹¤. ëŒ€í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }

async def handle_guided_mode(request: ChatbotRequest, session: Dict, llm_service: LLMService) -> Dict[str, Any]:
    """
    ê°€ì´ë“œ ëª¨ë“œ ì²˜ë¦¬ - ê¸°ì¡´ ê¸°ëŠ¥ë³„ ì§ˆë¬¸ ì²˜ë¦¬
    """
    current_index = session["current_index"]
    questions = session["questions"]
    current_field = session["current_field"]
    current_question = questions[current_index]["question"]

    # ê¸°ì¡´ LLM ì²˜ë¦¬ ë¡œì§
    llm_response = await llm_service.process_user_input(
        page=request.page,
        field=current_field,
        user_input=request.user_input,
        conversation_history=session["conversation_history"],
        questions=questions,
        current_index=current_index
    )

    # LLM ì‘ë‹µì—ì„œ ë°ì´í„° ì¶”ì¶œ
    value = llm_response.get("value")
    field = llm_response.get("field")
    message = llm_response.get("message", "")

    # í™•ì • ë‹µë³€ì´ ìˆìœ¼ë©´ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™
    if value is not None and field == current_field:
        if current_field not in session["completed_fields"]:
            session["completed_fields"].append(current_field)
        session["current_index"] += 1
        if session["current_index"] < len(questions):
            session["current_field"] = questions[session["current_index"]]["field"]
        else:
            message += "\n\nëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‰"

    return {
        "field": field,
        "value": value,
        "message": message
    } 